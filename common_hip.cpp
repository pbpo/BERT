#include "common_hip.hpp"
#include <numeric>
#include <random>

// ============================================================================
// GpuTensor Class Implementations
// ============================================================================

GpuTensor::GpuTensor(const std::string& name) : name_(name) {}

GpuTensor::GpuTensor(const std::vector<int>& dimensions, const std::string& name, DataType type)
    : dims_(dimensions), name_(name), dtype(type) {
    
    // ë””ë²„ê·¸ ë¡œê·¸ ì¶”ê°€
    fprintf(stderr, "[DEBUG] GpuTensor ìƒì„±ì: name='%s', dims.size()=%zu, dims=[", 
            name.c_str(), dimensions.size());
    for (size_t i = 0; i < dimensions.size(); ++i) {
        if (i > 0) fprintf(stderr, ", ");
        fprintf(stderr, "%d", dimensions[i]);
    }
    fprintf(stderr, "]\n");
    
    allocate(dims_);
    
    // í• ë‹¹ í›„ ì°¨ì› ì¬í™•ì¸
    fprintf(stderr, "[DEBUG] GpuTensor í• ë‹¹ í›„: name='%s', dims_.size()=%zu, dims_=[", 
            name_.c_str(), dims_.size());
    for (size_t i = 0; i < dims_.size(); ++i) {
        if (i > 0) fprintf(stderr, ", ");
        fprintf(stderr, "%d", dims_[i]);
    }
    fprintf(stderr, "], num_elements=%zu\n", num_elements_);
}

GpuTensor::~GpuTensor() {
    try {
        // ë™ê¸°í™” í›„ í•´ì œ
        if (allocated_ && d_ptr_ != nullptr) {
            hipError_t sync_err = hipDeviceSynchronize();
            if (sync_err == hipSuccess) {
                free();
            } else {
                std::cerr << "[WARNING] ë™ê¸°í™” ì‹¤íŒ¨, ê°•ì œ í•´ì œ: " << hipGetErrorString(sync_err) << std::endl;
                // ê°•ì œ í•´ì œ ì‹œë„
                if (!is_view_) {
                    hipFree(d_ptr_);
                }
                d_ptr_ = nullptr;
                allocated_ = false;
            }
        }
    } catch (...) {
        // ì†Œë©¸ìì—ì„œëŠ” ì˜ˆì™¸ë¥¼ ë˜ì§€ì§€ ì•ŠìŒ
        std::cerr << "[ERROR] GpuTensor ì†Œë©¸ìì—ì„œ ì˜ˆì™¸ ë°œìƒ" << std::endl;
    }
}

GpuTensor::GpuTensor(GpuTensor&& other) noexcept
    : d_ptr_(other.d_ptr_),
      dims_(std::move(other.dims_)),
      num_elements_(other.num_elements_),
      element_size_(other.element_size_),
      name_(std::move(other.name_)),
      allocated_(other.allocated_),
      dtype(other.dtype),
      is_view_(other.is_view_) {
    other.d_ptr_ = nullptr;
    other.allocated_ = false;
    other.is_view_ = false;
    other.num_elements_ = 0;
}

GpuTensor& GpuTensor::operator=(GpuTensor&& other) noexcept {
    if (this != &other) {
        free();
        d_ptr_ = other.d_ptr_;
        dims_ = std::move(other.dims_);
        num_elements_ = other.num_elements_;
        element_size_ = other.element_size_;
        name_ = std::move(other.name_);
        allocated_ = other.allocated_;
        dtype = other.dtype;
        is_view_ = other.is_view_;
        
        other.d_ptr_ = nullptr;
        other.allocated_ = false;
        other.is_view_ = false;
        other.num_elements_ = 0;
    }
    return *this;
}

void GpuTensor::allocate(const std::vector<int>& new_dims)
{
    /***********************
     * 0. ë·°(view) í•´ì œ ì²˜ë¦¬
     ***********************/
    if (is_view_) {
        d_ptr_   = nullptr;  // ì‹¤ì œ ë©”ëª¨ë¦¬ëŠ” ì†Œìœ í•˜ì§€ ì•ŠìŒ
        is_view_ = false;
        allocated_ = false;
        num_elements_ = 0;
    }

    /***********************
     * 1. ì°¨ì›/ìš©ëŸ‰ ê³„ì‚°
     ***********************/
    dims_ = new_dims;
    size_t new_elements = 1;
    for (int d : dims_) {
        if (d <= 0) { 
            // ğŸš¨ ìˆ˜ì •: 0 ì´í•˜ì˜ ì°¨ì›ì´ ìˆìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
            throw std::runtime_error("Invalid dimension " + std::to_string(d) + 
                                   " in tensor '" + name_ + "'. All dimensions must be positive.");
        }
        new_elements *= static_cast<size_t>(d);
    }

    // ğŸš¨ ì¶”ê°€: ì°¨ì› ë°°ì—´ì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²´í¬
    if (dims_.empty()) {
        throw std::runtime_error("Empty dimensions vector for tensor '" + name_ + "'");
    }

    // ğŸš¨ ì¶”ê°€: ë„ˆë¬´ í° í…ì„œ ì²´í¬ (ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)
    const size_t MAX_ELEMENTS = SIZE_MAX / sizeof(float) / 2;  // ì•ˆì „ ë§ˆì§„
    if (new_elements > MAX_ELEMENTS) {
        throw std::runtime_error("Tensor '" + name_ + "' too large: " + 
                               std::to_string(new_elements) + " elements");
    }

    if (new_elements == 0) {               // "ë¹ˆ" í…ì„œ
        free();                            // í˜¹ì‹œ ë‚¨ì•„ ìˆë˜ ë©”ëª¨ë¦¬ í•´ì œ
        return;
    }

    element_size_ = (dtype == DataType::INT32) ? sizeof(int) : sizeof(float);
    size_t new_bytes = new_elements * element_size_;
    size_t current_bytes = allocated_ ? num_elements_ * element_size_ : 0;

    /***********************
     * 2. ì¬í• ë‹¹ ì—¬ë¶€ ê²°ì •
     ***********************/
    if (!allocated_ || new_bytes != current_bytes) {
        free();               // ê¸°ì¡´ ê²ƒ í•´ì œ(ìˆë‹¤ë©´)

        /* 2-a) ë©”ëª¨ë¦¬ í™•ë³´ */
        // ğŸš¨ ì¶”ê°€: í• ë‹¹ ì „ ë””ë²„ê·¸ ì •ë³´

        
        hipError_t err = hipMalloc(&d_ptr_, new_bytes);
        if (err != hipSuccess) {
            d_ptr_ = nullptr; 
            allocated_ = false; 
            num_elements_ = 0;
            throw std::runtime_error(
                "hipMalloc failed for tensor '" + name_ + "': " +
                hipGetErrorString(err) + " (requested " + 
                std::to_string(new_bytes) + " bytes)");
        }

        // ğŸš¨ ì¶”ê°€: í• ë‹¹ëœ í¬ì¸í„° ê²€ì¦
        if (d_ptr_ == nullptr) {
            throw std::runtime_error("hipMalloc returned nullptr for tensor '" + name_ + "'");
        }
        
        // ğŸš¨ ì¶”ê°€: í¬ì¸í„° ìœ íš¨ì„± ê²€ì¦
        if (reinterpret_cast<uintptr_t>(d_ptr_) < 0x1000) {
            hipFree(d_ptr_);  // ì˜ëª»ëœ í¬ì¸í„°ì´ë¯€ë¡œ í•´ì œ
            d_ptr_ = nullptr;
            allocated_ = false;
            num_elements_ = 0;
            throw std::runtime_error("hipMalloc returned invalid pointer 0x" + 
                                   std::to_string(reinterpret_cast<uintptr_t>(d_ptr_)) + 
                                   " for tensor '" + name_ + "'");
        }

        allocated_ = true;
        num_elements_ = new_elements;
        
        printf("[DEBUG] %s: hipMalloc ì„±ê³µ - ptr=%p, bytes=%zu\n", 
               name_.c_str(), d_ptr_, new_bytes);

        /* 2-b) ìƒˆ ë²„í¼ë¥¼ 0 ìœ¼ë¡œ ì´ˆê¸°í™”(ë””ë²„ê¹…í•  ë•Œ ìœ ìš©) */
        err = hipMemset(d_ptr_, 0, new_bytes);
        if (err != hipSuccess) {
            printf("[WARNING] %s: hipMemset ì‹¤íŒ¨: %s\n", 
                   name_.c_str(), hipGetErrorString(err));
            // ì´ˆê¸°í™” ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
        }

    } else {
        /* í¬ê¸°ëŠ” ê°™ì§€ë§Œ ì¬ì‚¬ìš© â†’ ë‹¨ìˆœíˆ ìš”ì†Œ ìˆ˜ë§Œ ê°±ì‹  */
        num_elements_ = new_elements;
        printf("[DEBUG] %s: ë©”ëª¨ë¦¬ ì¬ì‚¬ìš© - ptr=%p, elements=%zu\n", 
               name_.c_str(), d_ptr_, num_elements_);
    }
}
void GpuTensor::allocate_if_smaller(const std::vector<int>& new_dims)
{
    size_t need = GpuTensor::count_elements(new_dims);   // â† ë³€ê²½
    if (!is_allocated() || need > num_elements_) {
        allocate(new_dims);          // ìƒˆ hipMalloc
    } else {
        dims_ = new_dims;            // ë©”ëª¨ë¦¬ëŠ” ê·¸ëŒ€ë¡œ, ëª¨ì–‘ë§Œ ê°±ì‹ 
    }
}
void GpuTensor::set_view(void* ptr, const std::vector<int>& new_dims, DataType type) {
    free();
    d_ptr_ = ptr;
    dims_ = new_dims;
    is_view_ = true;
    dtype = type;
    element_size_ = (dtype == DataType::INT32) ? sizeof(int) : sizeof(float);
    num_elements_ = 1;
    for (int dim : dims_) {
        num_elements_ *= dim;
    }
    allocated_ = (d_ptr_ != nullptr);
}

void GpuTensor::free() {
    // Only log if name is not empty to reduce noise
    if (!name_.empty()) {
        fprintf(stderr, "[%s] free() í˜¸ì¶œë¨: allocated_=%s, d_ptr_=%p, is_view_=%s, num_elements_=%zu\n",
                name_.c_str(), allocated_ ? "true" : "false", d_ptr_, is_view_ ? "true" : "false", num_elements_);
    }

    if (allocated_ && d_ptr_ != nullptr && !is_view_) {
        if (!name_.empty()) {
            fprintf(stderr, "[%s] hipFree í˜¸ì¶œ ì‹œë„...\n", name_.c_str());
        }

        // Use hipGetLastError to clear any pending errors before hipFree
        hipGetLastError();
        
        hipError_t err = hipFree(d_ptr_);

        if (!name_.empty()) {
            fprintf(stderr, "[%s] hipFree ì‹¤í–‰ ì™„ë£Œ: ë°˜í™˜ ì½”ë“œ(err)=%d, d_ptr_=%p -> nullptr\n",
                    name_.c_str(), err, d_ptr_);
        }

        d_ptr_ = nullptr;
        allocated_ = false;
        num_elements_ = 0;

        if (err != hipSuccess && err != hipErrorDeinitialized) {
            if (!name_.empty()) {
                fprintf(stderr, "!!!!!!!! [%s] hipFree ì˜¤ë¥˜: %s\n", name_.c_str(), hipGetErrorString(err));
            }
        }
    } else {
        // Clean up state for views or already freed tensors
        d_ptr_ = nullptr;
        allocated_ = false;
        num_elements_ = 0;
        is_view_ = false;
    }

    if (!name_.empty()) {
        fprintf(stderr, "[%s] free() ì¢…ë£Œ í›„ ìƒíƒœ: allocated_=%s, d_ptr_=%p, num_elements_=%zu\n\n",
                name_.c_str(), allocated_ ? "true" : "false", d_ptr_, num_elements_);
    }
}
void GpuTensor::zero_out(hipStream_t stream) {
    if (allocated_ && d_ptr_ != nullptr && num_elements_ > 0) {
        HIP_CHECK(hipMemsetAsync(d_ptr_, 0, size_in_bytes(), stream));
    }
}

template<typename T>
void GpuTensor::to_gpu(const std::vector<T>& data) {
    if (data.empty()) {
        allocate({0});
        return;
    }
    
    // ê¸°ì¡´ ì°¨ì› ì •ë³´ë¥¼ ìœ ì§€í•˜ê³ , ë°ì´í„° í¬ê¸°ë§Œ í™•ì¸
    if (dims_.empty()) {
        // ì°¨ì›ì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ 1ì°¨ì›ìœ¼ë¡œ ì„¤ì •
        std::vector<int> current_dims = {(int)data.size()};
        allocate(current_dims);
    } else {
        // ê¸°ì¡´ ì°¨ì› ì •ë³´ë¥¼ ìœ ì§€í•˜ê³  ë©”ëª¨ë¦¬ë§Œ í• ë‹¹
        size_t expected_elements = 1;
        for (int dim : dims_) {
            expected_elements *= dim;
        }
        
        if (data.size() != expected_elements) {
            throw std::runtime_error("Data size (" + std::to_string(data.size()) + 
                                   ") doesn't match tensor dimensions (" + 
                                   std::to_string(expected_elements) + ") for " + name_);
        }
        
        // ê¸°ì¡´ ì°¨ì›ì„ ìœ ì§€í•˜ë©´ì„œ ë©”ëª¨ë¦¬ í• ë‹¹
        if (!is_allocated() || num_elements_ != expected_elements) {
            allocate(dims_);  // ê¸°ì¡´ dims_ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        }
    }

    if (data.size() != num_elements_) {
        throw std::runtime_error("Tensor size mismatch for " + name_);
    }
    
    HIP_CHECK(hipMemcpy(d_ptr_, data.data(), size_in_bytes(), hipMemcpyHostToDevice));
}

template<typename T>
std::vector<T> GpuTensor::to_cpu() const {
    if (!allocated_ || d_ptr_ == nullptr || num_elements_ == 0) {
        return {};
    }
    std::vector<T> data(num_elements_);
    HIP_CHECK(hipMemcpy(data.data(), d_ptr_, size_in_bytes(), hipMemcpyDeviceToHost));
    return data;
}

void GpuTensor::copy_from_gpu(const GpuTensor& src, hipStream_t stream) {
    if (!src.is_allocated()) {
        throw std::runtime_error("Source tensor " + src.name_ + " is not allocated for copy.");
    }
    allocate(src.dims_);
    if (num_elements_ > 0) {
        HIP_CHECK(hipMemcpyAsync(d_ptr_, src.d_ptr_, src.size_in_bytes(), hipMemcpyDeviceToDevice, stream));
    }
}

// Explicit template instantiations
template void GpuTensor::to_gpu<float>(const std::vector<float>& data);
template std::vector<float> GpuTensor::to_cpu<float>() const;
template void GpuTensor::to_gpu<int>(const std::vector<int>& data);
template std::vector<int> GpuTensor::to_cpu<int>() const;


// ============================================================================
// Parameter Class Implementations
// ============================================================================
Parameter::Parameter(const std::vector<int>& weight_dims, const std::string& name)
    : weights(weight_dims, name + "_w"), has_bias_(false), name(name) {}

Parameter::Parameter(const std::vector<int>& weight_dims, const std::vector<int>& bias_dims, const std::string& name)
    : weights(weight_dims, name + "_w"), bias(bias_dims, name + "_b"), has_bias_(true), name(name) {}

void Parameter::initialize_random(float mean, float stddev) {
        if (!weights.is_allocated())  // â† ê¸°ì¡´ì— ì—†ìœ¼ë©´
        weights.allocate(weights.dims_);
    if (!bias.is_allocated() && bias.num_elements_ > 0)
        bias.allocate(bias.dims_);
    std::random_device rd;
    std::mt19937 gen(rd());
    std::normal_distribution<float> dist(mean, stddev);

    if (weights.is_allocated()) {
        std::vector<float> w_data(weights.num_elements_);
        for (auto& val : w_data) val = dist(gen);
        weights.to_gpu(w_data);
    }

    if (has_bias_ && bias.is_allocated()) {
        std::vector<float> b_data(bias.num_elements_, 0.0f);
        bias.to_gpu(b_data);
    }
}

void Parameter::allocate_gradients() {
        if (!grad_weights.is_allocated() && weights.is_allocated())
        grad_weights.allocate(weights.dims_);
    if (bias.num_elements_ && !grad_bias.is_allocated())
        grad_bias.allocate(bias.dims_);
    if (weights.is_allocated()) {
        ensure_allocated(grad_weights, weights.dims_);
        grad_weights.name_ = name + "_gw";
    }
    if (has_bias_ && bias.is_allocated()) {
        ensure_allocated(grad_bias, bias.dims_);
        grad_bias.name_ = name + "_gb";
    }
}